{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Clean codeV2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR-Q4AqdUc02",
        "outputId": "ff962824-5657-4014-9c8d-1270cb520bdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfhTtH8RFOQ1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pnryWHLCMCk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "import sklearn\n",
        "import string\n",
        "import math\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Embedding, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from string import punctuation\n",
        "from collections import defaultdict\n",
        "\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxpq160KA-6f"
      },
      "source": [
        "## File paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE1lG5_Rfv3Z"
      },
      "source": [
        "\n",
        "# Change path here\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/NLP/HateSpeechDetection/tweet_data/hateful_data.csv\"\n",
        "\n",
        "glove_file = datapath('/content/drive/MyDrive/NLP/HateSpeechDetection/tweet_data/glove.twitter.27B.25d.txt')\n",
        "\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "\n",
        "mode_save_path = \"/content/drive/MyDrive/NLP/HateSpeechDetection/saved_model.hdf5\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWsIjZZDHVd4"
      },
      "source": [
        "## Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAaNIMU7yzCT"
      },
      "source": [
        "vocab = {}\n",
        "freq = defaultdict(int)\n",
        "tweets = {}\n",
        "\n",
        "FLAGS = re.MULTILINE | re.DOTALL\n",
        "EMBEDDING_DIM = 25\n",
        "SEED = 42\n",
        "NO_OF_FOLDS = 10\n",
        "LOSS_FUN = \"categorical_crossentropy\"\n",
        "OPTIMIZER = \"adam\"\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "glove2word2vec(glove_file, word2vec_glove_file)\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_glove_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCvTrnHNczoC"
      },
      "source": [
        "# Replace smileys, usernames, urls with appropriate tags\n",
        "def get_tags(text):\n",
        "\n",
        "    # Regex expressions for identification \n",
        "    eyes = r\"[8:=;]\"\n",
        "    nose = r\"['`\\-]?\"\n",
        "    heart = \"<3\"\n",
        "    urls = \"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\"\n",
        "    hashtags = \"#\\S+\"\n",
        "    numbers = \"[-+]?[.\\d]*[\\d]+[:,.\\d]*\"\n",
        "    user_names = \"@\\w+\"\n",
        "\n",
        "    # replace patterns with a given tag\n",
        "    def re_sub(pattern, repl):\n",
        "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
        "\n",
        "    text = re_sub(r\"{}\".format(urls), \"<url>\")\n",
        "    text = re_sub(r\"{}\".format(hashtags), \"<hashtag>\")\n",
        "    text = re_sub(r\"{}\".format(numbers), \"<number>\")\n",
        "    text = re_sub(r\"{}\".format(user_names), \"<user>\")\n",
        "\n",
        "    # Get expressions\n",
        "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
        "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lol>\")\n",
        "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sad>\")\n",
        "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutral>\")\n",
        "    text = re_sub(r\"{}\".format(heart),\"<heart>\")\n",
        "    \n",
        "    return text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjNBB_gymNpL"
      },
      "source": [
        "# Tokenize tweets\n",
        "def tokenize(text):\n",
        "  text = get_tags(text)\n",
        "  words = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "  words = list(filter(lambda x:x not in STOPWORDS, words))\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5CdqTB8IB7l"
      },
      "source": [
        "## Get Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzXjAMkEf1qx"
      },
      "source": [
        "# Get tweets from csv files\n",
        "def get_tweets(path):\n",
        "  tweets = list()\n",
        "  df = pd.read_csv(path,sep=\",\", names=[\"class\", \"tweet\"], header=None)[1:]\n",
        "  print(df)\n",
        "  for i, row in df.iterrows():\n",
        "    tweets.append({\"text\": row[\"tweet\"], \"label\": row[\"class\"]})\n",
        "  return tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snfiB7iWCHdx",
        "outputId": "416d70f5-1eca-4309-9403-a99ad8f16a43"
      },
      "source": [
        "tweets = get_tweets(data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      class                                              tweet\n",
            "1         2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
            "2         1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
            "3         1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
            "4         1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
            "5         1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
            "...     ...                                                ...\n",
            "33095     2  lol at angry men writing me essays through Fac...\n",
            "33096     2  at least, I'm assuming that's what it was. I r...\n",
            "33097     2  Oh fuck me hard with a rusty chainsaw, another...\n",
            "33098     2      OMG SHUT UP DRASKO AND BIANCA #MKR #FINALFIVE\n",
            "33099     2                                   STFU drasko #MKR\n",
            "\n",
            "[33099 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwp8V4bxCK2Q"
      },
      "source": [
        "# Creates batches for k-fold cross validation\n",
        "def generate_batches(X, batch_size):\n",
        "    n_batches = X.shape[0]/float(batch_size)\n",
        "    n_batches = int(math.ceil(n_batches))\n",
        "    end = int(X.shape[0]/float(batch_size)) * batch_size\n",
        "    n = 0\n",
        "    for i in range(0,n_batches):\n",
        "        if i < n_batches - 1: \n",
        "            batch = X[i*batch_size:(i+1) * batch_size, :]\n",
        "            yield batch\n",
        "        else:\n",
        "            batch = X[end: , :]\n",
        "            n += X[end:, :].shape[0]\n",
        "            yield batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ba3R47Vdg8j"
      },
      "source": [
        "# Get vector representations from GloVe model for words in our vocabulary\n",
        "def get_embedding_weights():\n",
        "    embedding = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
        "    for k, v in vocab.items():\n",
        "        try:\n",
        "            embedding[v] = word2vec_model[k]\n",
        "        except:\n",
        "            pass\n",
        "    return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkbBmXlxdkO8"
      },
      "source": [
        "# Get tweets that have at least one word that is present in GloVe model\n",
        "def select_tweets():\n",
        "    tweets = get_tweets(data_path)\n",
        "    tweet_return = []\n",
        "    for tweet in tweets:\n",
        "        _emb = 0\n",
        "        words = tokenize(tweet['text'].lower())\n",
        "        \n",
        "        # Check if embedding already present in GLove model\n",
        "        if len(list(filter(lambda x: x in word2vec_model, words))) > 0:\n",
        "            tweet_return.append(tweet)\n",
        "\n",
        "    print('Number of tweets selected:', len(tweet_return))\n",
        "    return tweet_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvBdcmk8dXao"
      },
      "source": [
        "# Generate a vocabulary of words from the training tweets\n",
        "def generate_vocab():\n",
        "    vocab_index = 1\n",
        "    for tweet in tweets:\n",
        "        words = tokenize(tweet['text'].lower())\n",
        "        for word in words:\n",
        "            if word not in vocab:\n",
        "                vocab[word] = vocab_index\n",
        "                vocab_index += 1\n",
        "    vocab['UNK'] = len(vocab) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGbrnZfjd1Gg"
      },
      "source": [
        "# Generate sequences for the tweets. (Creates a number matrix for the tweets)\n",
        "def generate_sequence(tweets):\n",
        "    y_map = {\n",
        "        '0': 0,\n",
        "        '1': 1,\n",
        "        '2': 2\n",
        "    }\n",
        "\n",
        "    X, y = [], []\n",
        "    for tweet in tweets:\n",
        "        words = tokenize(tweet['text'].lower())\n",
        "        seq = []\n",
        "        for word in words:\n",
        "            seq.append(vocab.get(word, vocab['UNK']))\n",
        "        X.append(seq)\n",
        "        y.append(y_map[tweet['label']])\n",
        "    return X, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbcUhcvrd90f"
      },
      "source": [
        "# Build an LSTM model\n",
        "def lstm_model(sequence_length, embedding_dim):\n",
        "    model_variation = 'LSTM'\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(vocab)+1, embedding_dim, input_length=sequence_length))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss=LOSS_FUN, optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lWfgUbV_FWu"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRAJbZ6R_JGg",
        "outputId": "c20bda46-38c7-4461-dcb1-866ff57a0080"
      },
      "source": [
        "# Get tweets for training and generate sequence\n",
        "tweets = select_tweets()\n",
        "generate_vocab()\n",
        "X, y = generate_sequence(tweets)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      class                                              tweet\n",
            "1         2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
            "2         1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
            "3         1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
            "4         1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
            "5         1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
            "...     ...                                                ...\n",
            "33095     2  lol at angry men writing me essays through Fac...\n",
            "33096     2  at least, I'm assuming that's what it was. I r...\n",
            "33097     2  Oh fuck me hard with a rusty chainsaw, another...\n",
            "33098     2      OMG SHUT UP DRASKO AND BIANCA #MKR #FINALFIVE\n",
            "33099     2                                   STFU drasko #MKR\n",
            "\n",
            "[33099 rows x 2 columns]\n",
            "Number of tweets selected: 33031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX7oX4-M_nVX",
        "outputId": "1d72b48f-5cd0-4637-ecab-e84f4f79368e"
      },
      "source": [
        "# Pad zeroes to maintain uniform size\n",
        "MAX_SEQUENCE_LENGTH = max(map(lambda x:len(x), X))\n",
        "print (\"max seq length is %d\"%(MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "data = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y = np.array(y)\n",
        "data, y = sklearn.utils.shuffle(data, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max seq length is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU97dL4T_4L7"
      },
      "source": [
        "# Get embeddings\n",
        "W = get_embedding_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzicGcCq__qX"
      },
      "source": [
        "# Split data \n",
        "X_train, X_testing, y_train, y_testing = train_test_split(data, y, train_size=0.85, test_size=0.15, random_state=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgYp7M_mjhfx"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci4GTq4IssZp"
      },
      "source": [
        "# Print important training statistics\n",
        "def get_training_stats(y_test, y_pred, precision, recall, f1, m_precision, m_recall, m_f1):\n",
        "    print(\"Macro results...\")\n",
        "    print(\"Avg. Precision = %f\" %(precision/NO_OF_FOLDS))\n",
        "    print(\"Avg. Recall = %f\" %(recall/NO_OF_FOLDS))\n",
        "    print(\"Avg. R1 = %f\" %(f1/NO_OF_FOLDS))\n",
        "    print()\n",
        "    print(\"Micro results...\")\n",
        "    print(\"Avg. Precision = %f\" %(m_precision/NO_OF_FOLDS))\n",
        "    print(\"Avg. Recall = %f\" %(m_recall/NO_OF_FOLDS))\n",
        "    print(\"Avg. F1 = %f\" %(m_f1/NO_OF_FOLDS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YicN1C-XwubF"
      },
      "source": [
        "# Trains the model with 10 fold cross validation\n",
        "def train_LSTM(X, y, model, inp_dim, weights, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
        "    cv_object = KFold(n_splits=NO_OF_FOLDS, shuffle=True, random_state=42)\n",
        "    precision, recall, f1 = 0., 0., 0.\n",
        "    m_precision, m_recall, m_f1 = 0., 0., 0.\n",
        "    sentence_len = X.shape[1]\n",
        "    fold_number = 0\n",
        "    for train_index, test_index in cv_object.split(X):\n",
        "        fold_number += 1\n",
        "        print(\"Fold number =====>  \", fold_number)\n",
        "        model.layers[0].set_weights([weights])\n",
        "\n",
        "        X_train, y_train = X[train_index], y[train_index]\n",
        "        X_test, y_test = X[test_index], y[test_index]\n",
        "        y_train = y_train.reshape((len(y_train), 1))\n",
        "        X_temp = np.hstack((X_train, y_train))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for X_batch in generate_batches(X_temp, batch_size):\n",
        "                x = X_batch[:, :sentence_len]\n",
        "                y_temp = X_batch[:, sentence_len]\n",
        "\n",
        "                try:\n",
        "                    y_temp = np_utils.to_categorical(y_temp, num_classes=3)\n",
        "                except Exception as e:\n",
        "                    print (e)\n",
        "                    print (y_temp)\n",
        "\n",
        "                loss, acc = model.train_on_batch(x, y_temp)\n",
        "\n",
        "        y_pred = model.predict_on_batch(X_test)\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        # Track weighted precison, recall, f1\n",
        "        precision += precision_score(y_test, y_pred, average='weighted')\n",
        "        recall += recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 += f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Track micro precison, recall, f1\n",
        "        m_precision += precision_score(y_test, y_pred, average='micro')\n",
        "        m_recall += recall_score(y_test, y_pred, average='micro')\n",
        "        m_f1 += f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    model.save(mode_save_path)\n",
        "    get_training_stats(y_test, y_pred, precision, recall, f1, m_precision, m_recall, m_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5_AL_Ct1Tby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2d1228-5a00-4fc2-d7f1-2412566bc811"
      },
      "source": [
        "# Create and train LSTM model\n",
        "model = lstm_model(data.shape[1], EMBEDDING_DIM)\n",
        "train_LSTM(X_train, y_train, model, EMBEDDING_DIM, W)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 30, 25)            757175    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30, 25)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                15200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 153       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 772,528\n",
            "Trainable params: 772,528\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fold number =====>   1\n",
            "Fold number =====>   2\n",
            "Fold number =====>   3\n",
            "Fold number =====>   4\n",
            "Fold number =====>   5\n",
            "Fold number =====>   6\n",
            "Fold number =====>   7\n",
            "Fold number =====>   8\n",
            "Fold number =====>   9\n",
            "Fold number =====>   10\n",
            "Macro results...\n",
            "Avg. Precision = 0.919404\n",
            "Avg. Recall = 0.922889\n",
            "Avg. R1 = 0.920709\n",
            "\n",
            "Micro results...\n",
            "Avg. Precision = 0.922889\n",
            "Avg. Recall = 0.922889\n",
            "Avg. F1 = 0.922889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K8To54_jt74"
      },
      "source": [
        "## Load Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NICvDTIfYojU"
      },
      "source": [
        "model = load_model(mode_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVFL-4EPvGQS"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY4wQs27u-N5"
      },
      "source": [
        "# Print important testing statistics\n",
        "def get_testing_stats(y_test, y_pred):\n",
        "    print(\"Confusion matrix...\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print()\n",
        "    print(\"Classification report...\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print()\n",
        "    print(\"Accuracy = \", accuracy_score(y_test, y_pred)*100)\n",
        "    print()\n",
        "    print(\"Micro scores...\")\n",
        "    print(precision_recall_fscore_support(y_test, y_pred, average=\"micro\"))\n",
        "    print()\n",
        "    print(\"Micro scores per class\")\n",
        "    print(precision_recall_fscore_support(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omH93ii0DrrZ"
      },
      "source": [
        "def test_model(X_testing, y_testing):\n",
        "  y_pred = model.predict(X_testing)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  get_testing_stats(y_testing, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZLuRoq-EqZ2",
        "outputId": "2d9b217f-6d35-4848-a8b0-93763a48493c"
      },
      "source": [
        "# Test the model\n",
        "test_model(X_testing, y_testing)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f77f6424378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Confusion matrix...\n",
            "[[  80  124   23]\n",
            " [  67 2711  109]\n",
            " [   7   86 1748]]\n",
            "\n",
            "Classification report...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.35      0.42       227\n",
            "           1       0.93      0.94      0.93      2887\n",
            "           2       0.93      0.95      0.94      1841\n",
            "\n",
            "    accuracy                           0.92      4955\n",
            "   macro avg       0.79      0.75      0.76      4955\n",
            "weighted avg       0.91      0.92      0.91      4955\n",
            "\n",
            "\n",
            "Accuracy =  91.60443995963674\n",
            "\n",
            "Micro scores...\n",
            "(0.9160443995963673, 0.9160443995963673, 0.9160443995963673, None)\n",
            "\n",
            "Micro scores per class\n",
            "(array([0.51948052, 0.92810681, 0.92978723]), array([0.35242291, 0.93903706, 0.94948398]), array([0.41994751, 0.93353994, 0.93953238]), array([ 227, 2887, 1841]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHdnj76JvAW6"
      },
      "source": [
        "## Test single sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IXxoHzCdOdy"
      },
      "source": [
        "def test_sentence(text):\n",
        "  res_map = {\n",
        "          0: \"Hateful\",\n",
        "          1:'Offensive',\n",
        "          2:'Neutral'\n",
        "        }\n",
        "  words = tokenize(text.lower())\n",
        "  \n",
        "  seq = []\n",
        "  for word in words:\n",
        "      seq.append(vocab.get(word, vocab['UNK']))\n",
        "\n",
        "  y_predicted = model.predict(np.array([seq]))\n",
        "  print(y_predicted[0])\n",
        "  y_predicted = np.argmax(y_predicted, axis=1)\n",
        "\n",
        "  print(text + \"  :  \" + res_map[y_predicted[0]]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud5AeFqtC0en",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8731c563-9a2d-453a-cd22-87aac2e9a61f"
      },
      "source": [
        "test_sentence(\"@ard That lady is a bitch!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 30) for input Tensor(\"embedding_input_1:0\", shape=(None, 30), dtype=float32), but it was called on an input with incompatible shape (None, 3).\n",
            "[7.5882780e-03 9.9208844e-01 3.2322816e-04]\n",
            "@ard That lady is a bitch!  :  Offensive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l-5vTrpvkGu",
        "outputId": "382667ca-3d8f-469e-beb4-8a49968c3c66"
      },
      "source": [
        "test_sentence(\"@ard I hate those bastards. Burn in hell!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8.3764172e-01 1.6214721e-01 2.1106601e-04]\n",
            "@ard I hate those bastards. Burn in hell!!  :  Hateful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6cnVzh3z3ut",
        "outputId": "aca2f79e-d200-468f-9c42-4b8155daf53b"
      },
      "source": [
        "test_sentence(\"@ard He used to be very studious!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03756842 0.07198482 0.8904468 ]\n",
            "@ard He used to be very studious!!  :  Neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N9htfrCvAc6"
      },
      "source": [
        "## Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5gP7vItqoS5"
      },
      "source": [
        "def gen_data():\n",
        "    y_map = {\n",
        "            '0': 0,\n",
        "            '1': 1,\n",
        "            '2': 2\n",
        "            }\n",
        "\n",
        "    X, y = [], []\n",
        "    for tweet in tweets[:10]:\n",
        "        words = tokenize(tweet['text'].lower())\n",
        "        emb = np.zeros(EMBEDDING_DIM)\n",
        "        print(emb)\n",
        "        for word in words:\n",
        "            try:\n",
        "                emb += word2vec_model[word]\n",
        "            except:\n",
        "                pass\n",
        "        emb /= len(words)\n",
        "        X.append(emb)\n",
        "        y.append(y_map[tweet['label']])\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xocn_4Y-qy6u",
        "outputId": "f52a0c98-b18a-4bfa-d9a1-b84225de7f1a"
      },
      "source": [
        "X, y = gen_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXhl4RjJYgWr"
      },
      "source": [
        "list_of_texts = [tweet['text'] for tweet in tweets]\n",
        "list_of_labels = [tweet['label'] for tweet in tweets]\n",
        "\n",
        "\n",
        "base_x_train, base_x_test, base_y_train, base_y_test = train_test_split(list_of_texts, list_of_labels, train_size=0.85, test_size=0.15, random_state=SEED)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kPcoz1Ulz6b"
      },
      "source": [
        "def get_vector(X):\n",
        "  vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = tokenize,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,\n",
        "                             max_features = 300\n",
        "                             ) \n",
        "                             \n",
        "  vectorizer.fit(X)\n",
        "  vector = vectorizer.transform(X)\n",
        "  return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suNZ8QbPUw9c"
      },
      "source": [
        "def test_baseline_bow(model):\n",
        "  \n",
        "  train_data_features=get_vector(base_x_train).toarray()\n",
        "  model.fit(train_data_features, base_y_train)\n",
        "\n",
        "  test_data_features=get_vector(base_x_test).toarray()\n",
        "  result = model.predict(test_data_features)\n",
        "\n",
        "  get_testing_stats(base_y_test, result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwKWbTBUjWqm"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez9YfxUOfR2a",
        "outputId": "fea3ae3f-ccc5-4473-f21f-6a6ad7b7ae94"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators = 300)\n",
        "test_baseline_bow(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix...\n",
            "[[   6   87  114]\n",
            " [  41 2103  726]\n",
            " [  25  383 1470]]\n",
            "\n",
            "Classification report...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.03      0.04       207\n",
            "           1       0.82      0.73      0.77      2870\n",
            "           2       0.64      0.78      0.70      1878\n",
            "\n",
            "    accuracy                           0.72      4955\n",
            "   macro avg       0.51      0.51      0.51      4955\n",
            "weighted avg       0.72      0.72      0.72      4955\n",
            "\n",
            "\n",
            "Accuracy =  72.23007063572149\n",
            "\n",
            "Micro scores...\n",
            "(0.7223007063572149, 0.7223007063572149, 0.7223007063572149, None)\n",
            "\n",
            "Micro scores per class\n",
            "(array([0.08333333, 0.81733385, 0.63636364]), array([0.02898551, 0.73275261, 0.7827476 ]), array([0.04301075, 0.77273562, 0.70200573]), array([ 207, 2870, 1878]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5O65J6Rjbsz"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t61Fsxbpp8yy",
        "outputId": "58a9cd62-8edc-4903-bffa-993aeb19088b"
      },
      "source": [
        "model = LogisticRegression()\n",
        "test_baseline_bow(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix...\n",
            "[[   7   63  137]\n",
            " [  22 2007  841]\n",
            " [   7  250 1621]]\n",
            "\n",
            "Classification report...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.03      0.06       207\n",
            "           1       0.87      0.70      0.77      2870\n",
            "           2       0.62      0.86      0.72      1878\n",
            "\n",
            "    accuracy                           0.73      4955\n",
            "   macro avg       0.56      0.53      0.52      4955\n",
            "weighted avg       0.75      0.73      0.72      4955\n",
            "\n",
            "\n",
            "Accuracy =  73.36024217961655\n",
            "\n",
            "Micro scores...\n",
            "(0.7336024217961655, 0.7336024217961655, 0.7336024217961654, None)\n",
            "\n",
            "Micro scores per class\n",
            "(array([0.19444444, 0.86508621, 0.62370142]), array([0.03381643, 0.69930314, 0.86315229]), array([0.05761317, 0.7734104 , 0.72414563]), array([ 207, 2870, 1878]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJhSmbrjm2n"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEZDQdKLid1h",
        "outputId": "d08bd2af-12cf-4dca-a3f6-5d7712eef0d7"
      },
      "source": [
        "model = SVC()\n",
        "test_baseline_bow(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix...\n",
            "[[   0   74  133]\n",
            " [   0 2110  760]\n",
            " [   0  295 1583]]\n",
            "\n",
            "Classification report...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       207\n",
            "           1       0.85      0.74      0.79      2870\n",
            "           2       0.64      0.84      0.73      1878\n",
            "\n",
            "    accuracy                           0.75      4955\n",
            "   macro avg       0.50      0.53      0.51      4955\n",
            "weighted avg       0.74      0.75      0.73      4955\n",
            "\n",
            "\n",
            "Accuracy =  74.53077699293644\n",
            "\n",
            "Micro scores...\n",
            "(0.7453077699293643, 0.7453077699293643, 0.7453077699293643, None)\n",
            "\n",
            "Micro scores per class\n",
            "(array([0.        , 0.85114966, 0.63933764]), array([0.        , 0.73519164, 0.842918  ]), array([0.        , 0.78893251, 0.72714745]), array([ 207, 2870, 1878]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjsyYO5ijt1e"
      },
      "source": [
        "### Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL1h3Ucws-bq",
        "outputId": "853b252d-d87f-48ed-8d16-eb98438d8a8a"
      },
      "source": [
        "model = LinearSVC()\n",
        "test_baseline_bow(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix...\n",
            "[[   8   51  148]\n",
            " [  20 1987  863]\n",
            " [  15  186 1677]]\n",
            "\n",
            "Classification report...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.04      0.06       207\n",
            "           1       0.89      0.69      0.78      2870\n",
            "           2       0.62      0.89      0.73      1878\n",
            "\n",
            "    accuracy                           0.74      4955\n",
            "   macro avg       0.57      0.54      0.53      4955\n",
            "weighted avg       0.76      0.74      0.73      4955\n",
            "\n",
            "\n",
            "Accuracy =  74.10696266397578\n",
            "\n",
            "Micro scores...\n",
            "(0.7410696266397578, 0.7410696266397578, 0.7410696266397577, None)\n",
            "\n",
            "Weighted scores\n",
            "(0.7617204477146297, 0.7410696266397578, 0.7329433708464437, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEY5RsbhQvs_"
      },
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX2_qaIGkZBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b67d9d5-d190-419d-c249-082d5581a310"
      },
      "source": [
        "model = LinearSVC()\n",
        "test_baseline_bow(model)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix...\n",
            "[[   8   51  148]\n",
            " [  20 1987  863]\n",
            " [  15  186 1677]]\n",
            "\n",
            "Classification report...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.04      0.06       207\n",
            "           1       0.89      0.69      0.78      2870\n",
            "           2       0.62      0.89      0.73      1878\n",
            "\n",
            "    accuracy                           0.74      4955\n",
            "   macro avg       0.57      0.54      0.53      4955\n",
            "weighted avg       0.76      0.74      0.73      4955\n",
            "\n",
            "\n",
            "Accuracy =  74.10696266397578\n",
            "\n",
            "Micro scores...\n",
            "(0.7410696266397578, 0.7410696266397578, 0.7410696266397577, None)\n",
            "\n",
            "Micro scores per class\n",
            "(array([0.18604651, 0.89343525, 0.62388393]), array([0.03864734, 0.69233449, 0.89297125]), array([0.064     , 0.78013349, 0.73455979]), array([ 207, 2870, 1878]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWbRVkbm3pE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}